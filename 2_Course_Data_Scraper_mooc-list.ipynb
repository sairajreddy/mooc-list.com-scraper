{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract course features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Handle imports and set SSL\n",
    "\n",
    "from urllib.request import Request, urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import ssl\n",
    "import requests\n",
    "import re\n",
    "import json\n",
    "import csv\n",
    "\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the pickle file which consists of course list to load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"course_list_20181029.pkl\", 'rb') as pickleFile:\n",
    "    all_course_urls_set = list(pickle.load(pickleFile))\n",
    "\n",
    "len(all_course_urls_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In case you have already extracted the data and need to extract only the additional course data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with open(\"course_list_older_version.pkl\", 'rb') as pickleFile:\n",
    "#     all_course_urls_set_older_v = list(pickle.load(pickleFile))\n",
    "\n",
    "# with open(\"course_list_newer_version.pkl\", 'rb') as pickleFile:\n",
    "#     all_course_urls_set_newer_v = list(pickle.load(pickleFile))\n",
    "\n",
    "# additional_courses_urls = list(set(all_course_urls_set_newer_v) - set(all_course_urls_set_older_v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract course features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_basic_course_details_ML(url): \n",
    "\n",
    "\tbasic_course_info = {}\n",
    "\n",
    "\ttry:\n",
    "\t\thtml_req = Request(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "\t\thtml = urlopen(html_req, context=ctx).read()\n",
    "\texcept HTTPError as e:\n",
    "\t\tprint(e)\n",
    "\n",
    "\ttry:\n",
    "\t\tsoup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "\t\t# Course Name - Constant\n",
    "\t\tbasic_course_info['course_name'] = soup.findAll(\"h1\", {\"class\":\"page-title\"})[0].get_text()\n",
    "                                \n",
    "\t\t# Course Summary\n",
    "\t\tcourse_summary_div = soup.find(\"div\", {\"class\":\"intro-curso\"})\n",
    "\t\tif course_summary_div != None :\n",
    "\t\t\tcourse_summary_p = course_summary_div.find(\"p\")\n",
    "\t\t\tif course_summary_p != None :\n",
    "\t\t\t\tbasic_course_info['course_summary'] = course_summary_p.get_text()\n",
    "\t\t\telse :\n",
    "\t\t\t\tbasic_course_info['course_summary'] = None\n",
    "\t\telse :\n",
    "\t\t\tbasic_course_info['course_summary'] = None\n",
    "\n",
    "\t\t# Course Description\n",
    "\t\tcourse_description = soup.find(\"div\", {\"id\":\"corpoCurso\"}).findAll(\"p\")\n",
    "\t\tdescr = \"\"\n",
    "\t\tfor para in course_description :\n",
    "\t\t\tdescr = descr + para.get_text() + \"\\n\"\n",
    "\t\t\n",
    "\t\tbasic_course_info['course_description'] = descr\n",
    "\t\t\n",
    "\t\t# Number of Staff - {Various, Etc}\n",
    "\t\tnum_of_staff = soup.find(\"div\", {\"class\":\"field-instructors campo-info\"}).findAll(\"a\", {\"href\":re.compile(\"\\/instructor\\/+\")})\n",
    "\t\tif num_of_staff[0].get_text() == 'Various Instructors':\n",
    "\t\t\tbasic_course_info['num_of_staff'] = None\n",
    "\t\telse :\n",
    "\t\t\tif 'Various Instructors' in num_of_staff :\n",
    "\t\t\t\tbasic_course_info['num_of_staff'] = len(num_of_staff) - 1\n",
    "\t\t\telse :\n",
    "\t\t\t\tbasic_course_info['num_of_staff'] = len(num_of_staff)\n",
    "\n",
    "\t\t# Course duration {5 weeks, 5 Sessions, Course Not Available, Self-paced}\n",
    "\t\tcourse_duration = soup.find(\"a\", {\"href\":re.compile(\"\\/length\\/+\")})\n",
    "\t\tif course_duration != None :\n",
    "\t\t\tbasic_course_info['course_duration'] = course_duration.get_text()\n",
    "\t\telse :\n",
    "\t\t\tbasic_course_info['course_duration'] = None          \n",
    "\n",
    "\t\t# Course workload in hours per week {Range, Self-Study, Number, No Info}\n",
    "\t\tworkload = soup.find(\"a\", {\"href\":re.compile(\"\\/estimated-effort\\/+\")})\n",
    "\t\tif workload != None :\n",
    "\t\t\tbasic_course_info['workload'] = workload.get_text()\n",
    "\t\telse :\n",
    "\t\t\tbasic_course_info['workload'] = None\n",
    "\n",
    "\t\t# Compute number of days between two dates\n",
    "\t\tdef compute_days_difference(current_date, course_start_date) :\n",
    "\t\t\tsuffix = course_start_date.split(\" \")[1][-2:]            \n",
    "\t\t\tcourse_date_object = datetime.strptime(course_start_date, '%b %d' + suffix + ' %Y')\n",
    "\t\t\tdelta = current_date - course_date_object\n",
    "\t\t\treturn delta.days\n",
    "            \n",
    "\n",
    "\t\t# Course Start Date - Date, Self Paced\n",
    "\t\tcourse_start_date_div = soup.find(\"div\", {\"class\":\"field field-name-field-start-date-text field-type-text field-label-hidden\"})\n",
    "\t\tif course_start_date_div != None :\n",
    "\t\t\tcourse_start_date = course_start_date_div.find(\"div\", {\"class\":\"field-item even\"})\n",
    "\t\t\tif course_start_date != None :\n",
    "\t\t\t\tbasic_course_info['course_start_date'] = course_start_date.get_text()\n",
    "\t\t\t\tcourse_duration_text = basic_course_info['course_duration']\n",
    "\t\t\t\tmonths = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\t\t\t\tis_date = basic_course_info['course_start_date'][:3] in months\n",
    "\t\t\t\tif((is_date) and (course_duration_text != None)) and ('Week' in course_duration_text):\n",
    "\t\t\t\t\tdelta = compute_days_difference(datetime.now(), basic_course_info['course_start_date'])\n",
    "\t\t\t\t\tcourse_duration_days = int(course_duration_text.split(\" \")[0]) * 7\n",
    "\t\t\t\t\tif(delta<0) :\n",
    "\t\t\t\t\t\tbasic_course_info['is_course_active'] = 'No'                        \n",
    "\t\t\t\t\telif(delta < course_duration_days) :\n",
    "\t\t\t\t\t\tbasic_course_info['is_course_active'] = 'Yes'\n",
    "\t\t\t\t\telse :\n",
    "\t\t\t\t\t\tbasic_course_info['is_course_active'] = 'No'\n",
    "\t\t\t\telse :\n",
    "\t\t\t\t\tbasic_course_info['is_course_active'] = None\n",
    "\t\t\telse :\n",
    "\t\t\t\tbasic_course_info['course_start_date'] = None\n",
    "\t\t\t\tbasic_course_info['is_course_active'] = None\n",
    "\t\telse :\n",
    "\t\t\tbasic_course_info['course_start_date'] = None\n",
    "\t\t\tbasic_course_info['is_course_active'] = None\n",
    "            \n",
    "\t\t# Subject area\n",
    "\t\tsubject_area_div = soup.find(\"div\", {\"class\":\"field-categories campo-info\"})\n",
    "\t\tif subject_area_div != None :\n",
    "\t\t\tsubject_area_cats = subject_area_div.findAll(\"a\", {\"href\":re.compile(\"\\/categories\\/+\")})\n",
    "\t\t\tif len(subject_area_cats) != 0 : \n",
    "\t\t\t\tsubject_areas_string = \"\" \n",
    "\t\t\t\tfor subject_area in subject_area_cats :\n",
    "\t\t\t\t\tsubject_areas_string = subject_areas_string+subject_area.get_text()+\"; \"\n",
    "\t\t\t\tbasic_course_info['subject_area'] = subject_areas_string\n",
    "\t\t\telse :\n",
    "\t\t\t\tbasic_course_info['subject_area'] = None\n",
    "\t\telse :\n",
    "\t\t\tbasic_course_info['subject_area'] = None\n",
    "        \n",
    "\t\t# Course level\n",
    "\t\tcourse_level = soup.findAll(\"a\", {\"href\":re.compile(\"\\/course-level\\/+\")})\n",
    "\t\tif len(course_level) != 0 :\n",
    "\t\t\tbasic_course_info['course_level'] = course_level[0].get_text()\n",
    "\t\telse :\n",
    "\t\t\tbasic_course_info['course_level'] = None\n",
    "\n",
    "\t\t# Course base learning platform \n",
    "\t\tcourse_platform_div = soup.find(\"div\", {\"class\":\"field-initiative campo-info\"})\n",
    "\t\tif course_platform_div != None :\n",
    "\t\t\tcourse_platform_title = course_platform_div.find(\"a\", {\"href\":re.compile(\"\\/initiative\\/+\")})\n",
    "\t\t\tif course_platform_title != None : \n",
    "\t\t\t\tbasic_course_info['course_platform'] = course_platform_title.get_text() \n",
    "\t\t\telse :\n",
    "\t\t\t\tbasic_course_info['course_platform'] = None\n",
    "\t\telse :\n",
    "\t\t\tbasic_course_info['course_platform'] = None\n",
    "\n",
    "\t\t# University\n",
    "\t\tuniversity_div = soup.find(\"div\", {\"class\":\"field-university-entity campo-info\"})\n",
    "\t\tif university_div != None :\n",
    "\t\t\tuniversity_title = university_div.findAll(\"a\", {\"href\":re.compile(\"\\/university-entity\\/+\")})\n",
    "\t\t\tnum_of_univs = len(university_title)\n",
    "\t\t\tif num_of_univs != 0 : \n",
    "\t\t\t\tuniv_string = \"\"\n",
    "\t\t\t\tfor univ in university_title :\n",
    "\t\t\t\t\tuniv_string = univ_string + univ.get_text() + \"; \"\n",
    "\t\t\t\tbasic_course_info['university'] = univ_string\n",
    "\t\t\t\tbasic_course_info['num_of_univs'] = num_of_univs\n",
    "\t\t\telse :\n",
    "\t\t\t\tbasic_course_info['university'] = None\n",
    "\t\t\t\tbasic_course_info['num_of_univs'] = 0\n",
    "\t\telse :\n",
    "\t\t\tbasic_course_info['university'] = None\n",
    "\t\t\tbasic_course_info['num_of_univs'] = None\n",
    "\n",
    "\t\t# Country \n",
    "\t\tcountry_div = soup.find(\"div\", {\"class\":\"field-country campo-info\"})\n",
    "\t\tif country_div != None :\n",
    "\t\t\tcountry_title = country_div.find(\"a\", {\"href\":re.compile(\"\\/countries\\/+\")})\n",
    "\t\t\tif country_title != None : \n",
    "\t\t\t\tbasic_course_info['country'] = country_title.get_text() \n",
    "\t\t\telse :\n",
    "\t\t\t\tbasic_course_info['country'] = None\n",
    "\t\telse :\n",
    "\t\t\tbasic_course_info['country'] = None\n",
    "\n",
    "\t\t# Is the course graded?\n",
    "\t\tis_graded = soup.find(\"a\", {\"href\":re.compile(\"\\/exam\\/+\")})\n",
    "\t\tif is_graded != None :\n",
    "\t\t\tbasic_course_info['is_graded'] = is_graded.get_text()[0:3].strip()\n",
    "\t\t\tbasic_course_info['assessment_type'] = is_graded.get_text()\n",
    "\t\telse :\n",
    "\t\t\tbasic_course_info['is_graded'] = None\n",
    "\t\t\tbasic_course_info['assessment_type'] = None\n",
    "\n",
    "\t\t# Course Language\t{}\n",
    "\t\tbasic_course_info['language'] = soup.find(\"div\", {\"class\":\"field-language campo-info\"}).find(\"a\", {\"href\":re.compile(\"\\/language\\/+\")}).get_text()\n",
    "\t\tlanguage_div = soup.find(\"div\", {\"class\":\"field-language campo-info\"})\n",
    "\t\tif language_div != None :\n",
    "\t\t\tlanguage_title = language_div.findAll(\"a\", {\"href\":re.compile(\"\\/language\\/+\")})\n",
    "\t\t\tnum_of_langs = len(language_title)\n",
    "\t\t\tif num_of_langs != 0 : \n",
    "\t\t\t\tlang_string = \"\"\n",
    "\t\t\t\tfor lang in language_title :\n",
    "\t\t\t\t\tlang_string = lang_string + lang.get_text() + \"; \"\n",
    "\t\t\t\tbasic_course_info['language'] = lang_string\n",
    "\t\t\t\tbasic_course_info['num_of_langs'] = num_of_langs\n",
    "\t\t\telse :\n",
    "\t\t\t\tbasic_course_info['language'] = None\n",
    "\t\t\t\tbasic_course_info['num_of_langs'] = 0\n",
    "\t\telse :\n",
    "\t\t\tbasic_course_info['language'] = None\n",
    "\t\t\tbasic_course_info['num_of_langs'] = None\n",
    "\n",
    "\t\t# Course Certificate\n",
    "\t\tcertificate = soup.find(\"a\", {\"href\":re.compile(\"\\/certificate\\/+\")}).get_text()\n",
    "\t\tif('Paid' in certificate) :\n",
    "\t\t\tbasic_course_info['certificate'] = 'Paid'\n",
    "\t\telif('Free' in certificate) :\n",
    "\t\t\tbasic_course_info['certificate'] = 'Free'\n",
    "\t\telif(('No' in certificate) and ('No certificate information' != certificate)) :\n",
    "\t\t\tbasic_course_info['certificate'] = 'No'\n",
    "\t\telse :\n",
    "\t\t\tbasic_course_info['certificate'] = None\n",
    "\n",
    "\t\t# Course Certificate Fee\n",
    "\t\tcertificate = soup.find(\"div\", {\"class\":\"field-certificate-price campo-info\"})\n",
    "\t\tif(certificate!=None) :    \n",
    "\t\t\tcertificate_price = certificate.find(\"div\", {\"class\":\"field field-name-field-certificate-price field-type-number-decimal field-label-hidden\"}).find(\"div\", {\"class\":\"field-item even\"}).get_text()\n",
    "\t\t\tcertificate_currency = certificate.find(\"div\", {\"class\":\"field field-name-field-certificate-price-currency field-type-taxonomy-term-reference field-label-hidden\"}).find(\"div\", {\"class\":\"field-item even\"}).get_text()\n",
    "\t\t\tbasic_course_info['certificate_fee'] = certificate_price + \" \" + certificate_currency            \n",
    "\t\telse :\n",
    "\t\t\tbasic_course_info['certificate_fee'] = None\n",
    "            \n",
    "        \n",
    "\n",
    "\t\t# Variable attributes for each course that needs to be checked\n",
    "\t\tdef check_course_attribute(class_name) :\n",
    "\t\t\tif len(soup.findAll(\"i\", {\"class\":class_name})) == 1 :\n",
    "\t\t\t\treturn 'Yes'\n",
    "\t\t\telse :\n",
    "\t\t\t\treturn 'No'\n",
    "\n",
    "\t\t# Is Discussions Provided? (Forums)\n",
    "\t\tbasic_course_info['discussion_forum'] = check_course_attribute('fa fa-comment')\n",
    "\n",
    "\t\t# Is there a Collaborative Project?\n",
    "\t\tbasic_course_info['collaborative_project'] = check_course_attribute('fa fa-cogs')\n",
    "\n",
    "\t\t# Is additional material provided?\n",
    "\t\tbasic_course_info['additional_material'] = check_course_attribute('fa fa-book')\n",
    "\n",
    "\t\t# Is there a peer assessment activity? \n",
    "\t\tbasic_course_info['peer_assessment'] = check_course_attribute('fa fa-group')\n",
    "\n",
    "\t\t# Does it have video lectures?\n",
    "\t\tbasic_course_info['video_lectures'] = check_course_attribute('fa fa-film')\n",
    "\n",
    "\t\t# Does it have audio lectures?\n",
    "\t\tbasic_course_info['audio_lectures'] = check_course_attribute('fa fa-headphones')\t\n",
    "\n",
    "\t\t# Average rating (Rating, Number of Votes)\n",
    "\t\trating = soup.find(\"div\", {\"id\":\"corpoCurso\"})\n",
    "\t\taverage_rating_10_span_1 = rating.find(\"span\", {\"class\":\"average-rating\"})\n",
    "\t\tif average_rating_10_span_1 != None :\n",
    "\t\t\tbasic_course_info['average_rating_10'] = average_rating_10_span_1.find(\"span\").get_text()\n",
    "\t\telse :\n",
    "\t\t\tbasic_course_info['average_rating_10'] = 0\n",
    "            \n",
    "\t\tnum_of_votes_span_1 = rating.find(\"span\", {\"class\":\"total-votes\"})\n",
    "\t\tif num_of_votes_span_1 != None :\n",
    "\t\t\tbasic_course_info['num_of_votes'] = num_of_votes_span_1.find(\"span\").get_text()\n",
    "\t\telse :\n",
    "\t\t\tbasic_course_info['num_of_votes'] = 0\n",
    "            \n",
    "\t\tdef final_location(url):\n",
    "\t\t\ttry:\n",
    "\t\t\t\theaders = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.106 Safari/537.36',}\n",
    "\t\t\t\tresponse = requests.get(url, timeout=3 , allow_redirects=False , headers=headers)\n",
    "\t\t\texcept requests.exceptions.HTTPError as errh:\n",
    "\t\t\t\treturn url\n",
    "\t\t\texcept requests.exceptions.ConnectionError as errc:\n",
    "\t\t\t\treturn url\n",
    "\t\t\texcept requests.exceptions.Timeout as errt:\n",
    "\t\t\t\treturn url\n",
    "\t\t\texcept requests.exceptions.RequestException as err:\n",
    "\t\t\t\treturn url\n",
    "\n",
    "\t\t\tif response.headers.get(\"Location\"):\n",
    "\t\t\t\treturn final_location(response.headers.get(\"Location\"))\n",
    "\t\t\telse:\n",
    "\t\t\t\treturn response.url\n",
    "\n",
    "\t\t# Course URL - \n",
    "\t\tcourse_url_div = soup.find(\"div\", {\"class\":\"row gotoCurso\"})\n",
    "\t\tif course_url_div != None :\n",
    "\t\t\tcourse_url = course_url_div.find(\"a\")\n",
    "\t\t\tif course_url != None :\n",
    "\t\t\t\tcourse_url_text = course_url['href']\n",
    "\t\t\t\tbasic_course_info['course_url'] = final_location(course_url_text)\n",
    "\t\t\telse :\n",
    "\t\t\t\tbasic_course_info['course_url'] = None\n",
    "\t\telse :\n",
    "\t\t\tbasic_course_info['course_url'] = None\n",
    "\n",
    "            \n",
    "\texcept AttributeError as e:\n",
    "\t\tprint(e)\n",
    "\n",
    "\treturn basic_course_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For each course URL, extract the features and append it to CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RENAME the FILE based on the date you are extracting -- course_list_YEARMONTHDATE.csv\n",
    "# NOTE : This takes lot of time as it needs to loop through every page \n",
    "# Please make sure you have uninterrupted internet\n",
    "\n",
    "with open(\"mooc_list_data_20181029.csv\", \"w\") as file_2:\n",
    "    writer = csv.writer(file_2, dialect='excel')\n",
    "    writer.writerow(['Course Name', 'Course Summary', 'Course Description', 'Number of Staff', 'Course Duration', 'Workload (Hours per Week)', 'Course Start Date', 'Is_Course_Active', 'Subject Area', 'Course Level', 'Course Platform', 'Unievrsities', 'Number of Universities', 'Country', 'Is_Graded', 'Assessment Type', 'Language', 'Number of Languages', 'Certificate', 'Certificate Fee', 'Discussion Forum', 'Collaborative Project', 'Additional Material', 'Peer Assessment', 'Video Lectures', 'Audio Lectures', 'Average Rating (10)', 'Number of Votes', 'Course URL'])\n",
    "    \n",
    "    # In case a course page is incosistent, the course URL is added to the list which can be inspected later\n",
    "    had_issues = []\n",
    "    \n",
    "    # START EXTRACT\n",
    "    \n",
    "    for i, course_url in enumerate(all_course_urls_set) :\n",
    "        try :\n",
    "            print(i)\n",
    "            course_details = get_basic_course_details_ML(course_url)\n",
    "            writer.writerow(list(course_details.values()))\n",
    "        except :\n",
    "            print(course_url)\n",
    "            had_issues.append(course_url)\n",
    "    \n",
    "    # END EXTRACT\n",
    "\n",
    "# NOTE : Uncomment the following code if you have to extract only additional courses\n",
    "# ALSO NOTE : Comment the above code starting from label \"START EXTRACT\"  to \"END EXTRACT\"\n",
    "\n",
    "#     for i, course_url in enumerate(additional_courses_urls) :\n",
    "#         try :\n",
    "#             print(i)\n",
    "#             course_details = get_basic_course_details_ML(course_url)\n",
    "#             writer.writerow(list(course_details.values()))\n",
    "#         except :\n",
    "#             print(course_url)\n",
    "#             had_issues.append(course_url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
